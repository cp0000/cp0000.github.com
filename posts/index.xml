<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on CP0000 - 一只特立独行的猪</title>
    <link>https://cp0000.github.io/posts/</link>
    <description>Recent content in Posts on CP0000 - 一只特立独行的猪</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>CP0000</copyright>
    <lastBuildDate>Mon, 25 Nov 2024 20:31:37 +0800</lastBuildDate><atom:link href="https://cp0000.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Review OmniGen: Unified Image Generation</title>
      <link>https://cp0000.github.io/posts/review_omnigen/</link>
      <pubDate>Mon, 25 Nov 2024 20:31:37 +0800</pubDate>
      
      <guid>https://cp0000.github.io/posts/review_omnigen/</guid>
      <description>OmniGen： A new diffusion model for unified image generation. OmniGen no longer requires additional modules such as ControlNet or IP-Adapter to process diverse control conditions. https://github.com/VectorSpaceLab/OmniGen https://arxiv.org/abs/2409.11340 简介 本文推出一种新的统一的文生图扩散模型：OmniGen. 相较于之前的 S</description>
    </item>
    
    <item>
      <title>Review_VASA-1</title>
      <link>https://cp0000.github.io/posts/review_vasa-1/</link>
      <pubDate>Mon, 20 May 2024 19:36:57 +0800</pubDate>
      
      <guid>https://cp0000.github.io/posts/review_vasa-1/</guid>
      <description>VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time https://www.microsoft.com/en-us/research/project/vasa-1/ 微软的一篇关于 talking head 的工作，叫：VASA-1。VASA-1 是利用一段音频和一张照片，生成一段该照片说话的视频。 他的核心贡献</description>
    </item>
    
    <item>
      <title>Review_PuLID</title>
      <link>https://cp0000.github.io/posts/review_pulid/</link>
      <pubDate>Tue, 30 Apr 2024 15:55:05 +0800</pubDate>
      
      <guid>https://cp0000.github.io/posts/review_pulid/</guid>
      <description>本文介绍一篇关于人脸保ID的工作 PuLID: Pure and Lightning ID Customization via Contrastive Alignment 主要的贡献在于： （1）之前的保ID方法，在底座风格模型上加入人脸ID之后，会丢失底座模型的</description>
    </item>
    
    <item>
      <title>Review EMO</title>
      <link>https://cp0000.github.io/posts/review_emo/</link>
      <pubDate>Mon, 04 Mar 2024 14:45:17 +0800</pubDate>
      
      <guid>https://cp0000.github.io/posts/review_emo/</guid>
      <description>主页： EMO 简介： 阿里最新的一片 talking head 的工作，输入为一张 reference image 和 一段音频，生成一段视频。EMO 这篇工作生成的视频结果，其视频生成结果稳定，帧间一致性</description>
    </item>
    
    <item>
      <title>Sora 是如何工作的？</title>
      <link>https://cp0000.github.io/posts/how_sora_works/</link>
      <pubDate>Tue, 20 Feb 2024 16:10:03 +0800</pubDate>
      
      <guid>https://cp0000.github.io/posts/how_sora_works/</guid>
      <description>OpenAI 于2024.2.16 发布了视频生成模型Sora，Sora可以生成时长1分钟的高清视频，其生成质量非常惊人。 Demo: https://cdn.openai.com/tmp/s/title_0.mp4 官网地址：Sora 技术报告：</description>
    </item>
    
    <item>
      <title>我的2023</title>
      <link>https://cp0000.github.io/posts/my_2023/</link>
      <pubDate>Tue, 13 Feb 2024 20:03:37 +0800</pubDate>
      
      <guid>https://cp0000.github.io/posts/my_2023/</guid>
      <description>疫情结束 在23年的元旦前后，随着国内的清零政策放开，疫情一波大爆发之后，新冠在23年从人们的生活中消散了。持续3年的疫情终于结束了。在23年</description>
    </item>
    
    <item>
      <title>Reivew: MobileDiffusion</title>
      <link>https://cp0000.github.io/posts/mobile_diffusion/</link>
      <pubDate>Tue, 06 Feb 2024 17:44:15 +0800</pubDate>
      
      <guid>https://cp0000.github.io/posts/mobile_diffusion/</guid>
      <description>本文主要介绍 Google 最新的一篇关于如何把 diffusion 模型 port 到移动端设备上的论文 MobileDiffusion: Subsecond Text-to-Image Generation on Mobile Devices。google 的博客上有相关的英文blog：http</description>
    </item>
    
    <item>
      <title>Review: Animate Anyone: Consistent and Controllable Image-to-Video Synthesis for Character Animation</title>
      <link>https://cp0000.github.io/posts/animate_anyone/</link>
      <pubDate>Thu, 11 Jan 2024 19:34:35 +0800</pubDate>
      
      <guid>https://cp0000.github.io/posts/animate_anyone/</guid>
      <description>这一篇关于 Animate Anyone 的读书笔记。Animate Anyone介绍了一种能够根据图像以及结合动作姿态序列生成一段动作视频的方法。 方法结构图 方法归纳为以</description>
    </item>
    
    <item>
      <title>活到35</title>
      <link>https://cp0000.github.io/posts/35/</link>
      <pubDate>Sun, 12 Nov 2023 14:43:46 +0800</pubDate>
      
      <guid>https://cp0000.github.io/posts/35/</guid>
      <description>年龄焦虑 35了，国内互联网公司有着35岁失业的说法，国内的考公也要求35岁以下。我想在国内从事互联网相关工作的绝大多数人都会有年龄方面的焦虑</description>
    </item>
    
    <item>
      <title>Review:Emu: Enhancing Image Generation Models Using Photogenic Needles in a Haystack</title>
      <link>https://cp0000.github.io/posts/review_emu/</link>
      <pubDate>Mon, 09 Oct 2023 17:28:31 +0800</pubDate>
      
      <guid>https://cp0000.github.io/posts/review_emu/</guid>
      <description>本文提出一个基于latent diffusion框架的文生图模型Emu；利用小量~2000张高质量图片，对pre-trained模型进行qua</description>
    </item>
    
    <item>
      <title>Review: IP-Adapter: Text Compatible Image Prompt Adapter for Text-to-Image Diffusion Modelsb</title>
      <link>https://cp0000.github.io/posts/review_ip_adapter/</link>
      <pubDate>Mon, 09 Oct 2023 17:12:39 +0800</pubDate>
      
      <guid>https://cp0000.github.io/posts/review_ip_adapter/</guid>
      <description>本文提出一种 Image Prompt Adapter 方案，实现了类似 Image Prompt的方案。从上图，我们可以看到通过IP-Adapter，我们可以实现（1）Image Varia</description>
    </item>
    
    <item>
      <title>GigaGAN文生图：Scaling up GANs for Text-to-Image Synthesis</title>
      <link>https://cp0000.github.io/posts/review_gigagan/</link>
      <pubDate>Fri, 25 Aug 2023 19:15:51 +0800</pubDate>
      
      <guid>https://cp0000.github.io/posts/review_gigagan/</guid>
      <description>这是一篇关于 https://arxiv.org/abs/2303.05511 的笔记。 近两年基于扩散概率模型和自回归模型的文生图大模型发展迅速。20，21年的SOTA生成网络GAN在这一波文生图大模型发展</description>
    </item>
    
    <item>
      <title>Stable Diffusion XL 技术报告</title>
      <link>https://cp0000.github.io/posts/review_sdxl/</link>
      <pubDate>Wed, 09 Aug 2023 00:26:46 +0800</pubDate>
      
      <guid>https://cp0000.github.io/posts/review_sdxl/</guid>
      <description>前言 这是一篇关于 **SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis 技术报告的中文翻译。 SDXL 是 Stability AI 继 SD 1.5， SD 2.0 之后发布的一个新的文生图模型。目前该模型在 reddit 上讨论还是蛮热烈的</description>
    </item>
    
    <item>
      <title>文生图 Imagen 扩散模型简介</title>
      <link>https://cp0000.github.io/posts/review_imagen/</link>
      <pubDate>Thu, 01 Jun 2023 20:17:11 +0800</pubDate>
      
      <guid>https://cp0000.github.io/posts/review_imagen/</guid>
      <description>Review Imagen 本文是对论文 Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding 的简介 Imagen 是 Google 在22年5月发表的一篇关于文生图任务的论文。其主体框架基于 Diffusion 模型。和其他文生图（比如 DALLE-</description>
    </item>
    
    <item>
      <title>文生图扩散模型</title>
      <link>https://cp0000.github.io/posts/text-to-image-diffusion-survey/</link>
      <pubDate>Tue, 09 May 2023 15:58:14 +0800</pubDate>
      
      <guid>https://cp0000.github.io/posts/text-to-image-diffusion-survey/</guid>
      <description>Text-to-image Diffusion Models in Generative AI: A Survey 本文是关于 Text-to-image Diffusion Models in Generative AI:A Survey 的翻译和摘要。 自2021年2月 OpenAI 推出 DALL- E 之后，文生图进入了AI研究人员和大众的视野。伴随着22年 DALL-E 2</description>
    </item>
    
    <item>
      <title>读书笔记：《认知觉醒：开启自我改变的原动力》</title>
      <link>https://cp0000.github.io/posts/cognitive_awakening/</link>
      <pubDate>Sun, 23 Apr 2023 22:08:46 +0800</pubDate>
      
      <guid>https://cp0000.github.io/posts/cognitive_awakening/</guid>
      <description>《认知觉醒：开启自我改变的原动力》是一本很好读的书，他帮助我相对系统性的理清了自己这些年潜意识中模糊存在的道理。这本书给我最明显的收获有两点</description>
    </item>
    
    <item>
      <title>关于投资</title>
      <link>https://cp0000.github.io/posts/my_investment/</link>
      <pubDate>Wed, 29 Mar 2023 19:41:20 +0800</pubDate>
      
      <guid>https://cp0000.github.io/posts/my_investment/</guid>
      <description>工具 学生时代，没有任何的储蓄，对投资理财没有任何概念。工作之后，早期收入比较少，没有意识需要去做投资。我想可能很多人和我一样，第一次亲手操作</description>
    </item>
    
    <item>
      <title>2023年春节</title>
      <link>https://cp0000.github.io/posts/2023_chinese_new_year/</link>
      <pubDate>Sun, 29 Jan 2023 22:37:24 +0800</pubDate>
      
      <guid>https://cp0000.github.io/posts/2023_chinese_new_year/</guid>
      <description>2023年春节是自新冠疫情爆发以来的第一个社会面开放的中国新年，还没回家之前，听说回家过年的人很多。我这次选择了开车回家，从上海到安徽，40</description>
    </item>
    
    <item>
      <title>我的2022</title>
      <link>https://cp0000.github.io/posts/my_2022/</link>
      <pubDate>Sat, 31 Dec 2022 18:33:20 +0800</pubDate>
      
      <guid>https://cp0000.github.io/posts/my_2022/</guid>
      <description>生活的本质是变化，而人类的本性是抗拒变化。 - 《也许你该找个人聊聊》 新冠之年 2022是被新冠支配的一年。年初，上海封城三个月，那段时间的焦虑与</description>
    </item>
    
    <item>
      <title>活到34</title>
      <link>https://cp0000.github.io/posts/34/</link>
      <pubDate>Sun, 13 Nov 2022 20:31:41 +0800</pubDate>
      
      <guid>https://cp0000.github.io/posts/34/</guid>
      <description>莫听穿林打叶声，何妨吟啸且徐行。竹杖芒鞋轻胜马，谁怕？一蓑烟雨任平生。 料峭春风吹酒醒，微冷，山头斜照却相迎。回首向来萧瑟处，归去，也无风雨也</description>
    </item>
    
  </channel>
</rss>
