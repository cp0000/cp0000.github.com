<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2018s on CP0000 - 一只特立独行的猪</title>
    <link>https://cp0000.github.io/2018/</link>
    <description>Recent content in 2018s on CP0000 - 一只特立独行的猪</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Sun, 18 Nov 2018 22:00:21 +0000</lastBuildDate><atom:link href="https://cp0000.github.io/2018/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>全卷积网络-语义分割的简介</title>
      <link>https://cp0000.github.io/2018/11/18/review-fcn/</link>
      <pubDate>Sun, 18 Nov 2018 22:00:21 +0000</pubDate>
      
      <guid>https://cp0000.github.io/2018/11/18/review-fcn/</guid>
      <description> 这是一篇译文，原文Review: FCN (Semantic Segmentation))
本文主要记录用于语义分割的全卷积网络。和分类，检测任务相比，分割是更难的一种任务。
图片分类：对图像进行分类 物体检测：检测一张图片中存在的物体，并给出物体的区域。 分割：为图像中的每个像素分类。 一个语义分割的例子：
该论文发表于 2015 CVPR，现在有 6000 次引用。它也是使用FCN进行语义分割的最基础的论文之一。
本文包括 从图像分类到语义分割 利用反卷积进行上采样 融合输出 结论 1.从图像分类到语义分割 传统意义上的分类任务，输入图像会缩小尺寸，并通过卷积层和全连接层，最终输出关于输入图片的标签，如下图：
想象我们把上图中的全连接层替换成 1X1 卷积层：
如果图像没有缩小尺寸，输出将不是单个标签。相反，输出的大小小于输入图像（由于最大池化层）
如果我们对上面的输出进行上采样，那么我们逐像素输出标签贴图，如下所示：
2.利用反卷积进行上采样 卷积是一个使输出尺寸变小的过程。反卷积就是一上采样，使得输出尺寸变大的过程（但不要把反卷积曲解成卷积的逆向操作），反卷积也被称为上卷积和转置卷积。当使用分数步幅时，也被称为分数步幅卷积。
3.融合输出 经过如下图所示的conv7后，输出尺寸很小，然后进行32X 上采样，得到和输入同样大小的输出。但也会把输出标签变得很糙。这个叫 FCN-32s:
这是因为在网络变深的时候能够获得深层次的特征，但如此同时空间位置信息也会丢失。这意味着浅网络可以获得更多的位置信息。如果我们把两种网络合并在一起，我们可以平衡结果。
为了组合，我们融合输出（通过元素添加）：
**FCN-16s:**的输出是把pool5的输出2倍上采样和pool4融合并进行16次上采样。**FCN-8s:**操作如上图所示，也是类似。
FCN-32s由于位置信息丢失结果非常粗糙，而FCN-8s的结果最好。
这种融合操作实际上就像AlexNet,VGGNet和GoogleNet中使用的增强/整合技术一样，它们通过多个模型结果的叠加，使预测更准确。但在这个任务中，它是针对每个像素去做的，并且它是拿模型中不同层的结果去叠加的。
4.结果 FCN-8s在Pascal VOC 2011数据集上效果最佳 FCN-16s在NYUDv2数据集上效果最佳 FCN-16s在SIFT数据集上效果最佳 第四行显示了一个失败案例：网络把船上的救生衣当作了人。
希望将来能够更多地阅读有关语义分割的深度学习技术。
References [2015 CVPR] [FCN] Fully Convolutional Networks for Semantic Segmentation [2017 TPAMI] [FCN] Fully Convolutional Networks for Semantic Segmentation </description>
    </item>
    
    <item>
      <title>超分FSRCNN的简介</title>
      <link>https://cp0000.github.io/2018/11/06/review-fsrcnn/</link>
      <pubDate>Tue, 06 Nov 2018 00:24:40 +0000</pubDate>
      
      <guid>https://cp0000.github.io/2018/11/06/review-fsrcnn/</guid>
      <description>这是一篇译文，原文Review:FSRCNN(Super Resolution)
本文主要用来概述一篇实时超分辨率的实现FSRCNN，全称Fast Super-Resolution Convolutional Neural Network，FSRCNN 发表于2016年的ECCV，目前为止有近300次的引用。 FSRCNN有着一个相对浅的网络结构，浅网络层让我们比较好理解每一个网络层的用途。与SRCNN相比，它重建后的图像质量更高。
对比SRCNN，FSRCNN-s(FSRCNN小模型版本)，FSRCNN-s 有着更好的PSNR（图像质量），更快的处理时长。 对比 SRCNN-Ex（SRCNN优质版本）和 FSRCNN，FSRCNN的结果PSNR更好，处理速度更快。 所以，来看下FSRCNN是如何达到质量和速度双优的
下文包含如下内容：
SRCNN 简述 FSRCNN 网络架构 如何利用 1x1 卷积对网络进行压缩和扩大 如何利用多个 3X3 卷积实现非线性映射 对比实验 结论 上图是 SRCNN 和 FSRCNN 的网络架构图。其中 Conv(f,n,c)表示该卷积： 卷积大小为fxf， 有n个过滤器以及c个输入通道。
1. SRCNN简述 SRCNN 的处理过程如下：
对输入图片利用双立方采样做上采样，使得其分辨率为目标分辨率 然后分别利用 9x9, 1x1, 5x5 的卷积来提高图片质量。其中 1x1 卷积是用来把低分辨率（LR）图像向量非线性映射为高分辨率 (HR) 图像向量. 计算复杂度为：
计算复杂度和HR图像大小成线性比例，SHR。HR图像越大，复杂度越高。
2. FSRCNN 网络结构 FSRCNN 包含如下五个主要处理步骤：
特征提取：利用一个 5x5 卷积代替 SRCNN 中的双立方差值 压缩：利用 1x1 卷积把特征层从 d 压缩为 s，其中 s 小于 d 非线性映射：多个 3x3 网络层代替单个的宽网络层 扩大： 1x1 卷积把特征层从 s 扩大为 d 反卷积： 利用 9x9 过滤器重建 HR 图像 以上结构就是 FSRCNN(d,s,m).</description>
    </item>
    
    <item>
      <title>活到30</title>
      <link>https://cp0000.github.io/2018/11/04/30/</link>
      <pubDate>Sun, 04 Nov 2018 20:08:40 +0000</pubDate>
      
      <guid>https://cp0000.github.io/2018/11/04/30/</guid>
      <description>有一天我做了一个恐怖的梦，梦见我32岁了。然后当我醒来，发现自己只有23岁，就放心了。但是后来我真的从梦里醒来，发现自己确实是32岁了。时间过得很快，20岁是人生的巅峰状态，从那以后我们就开始走下坡路了。 &amp;ndash; 电影《before the sunset》
少年时听长辈说某件事是10年之前发生的了，会觉得：“哇，10年啊，好久之前发生的事情啊”。如今才发现，10年之前发生的事情却仿佛就在眼前。08年的夏天，我刚上完大一，暑假没事在家里待着，每天守着电视看北京奥运会。电视里各种各样的奥运项目让人应接不暇，看着每个运动员健康矫捷美丽的身姿，我心想人应该活的如此健康快乐才是。
你发现每个你遇到的人，都尝试把环境变得更好，赚更多钱，赢得更多尊重，得到更多的赞赏，这真令人精疲力尽。 &amp;ndash; 电影《before the sunset》
11年从大学毕业之后，我便入了程序员这个行当；这是一个适合平民百姓，没啥背景出身的人干的行业。在这个行业只要你技术好，为人靠谱，可以靠着这门手艺安身立命。程序员工作中，和机器打交道多过和人打交道，这样想来我算是误打误撞入了一个和我性格挺搭的行业。 七年多的程序员生涯，我有过一些那种恍然大悟，让人分泌多巴胺的快乐时刻。
只是我最近在思考，程序员工作的意义到底在哪里？可能我所在的行业不是那种基建性质的系统软件开发，程序员在日常生活中，大多数时候做的事情只是担当老板，产品，运营同事们需求的实现者。当中除了如何实现有自己的主见之外，要实现什么完全是听别人的指挥。这听起来是一份没有honor的行当。不过有人会说，其实产品，运营，和其他各种各样形形色色的行业，多数时刻我们都是执行任务的角色。我们受制于人，每天按部就班，小心翼翼的处理事情，保证问题不要出在自己身上。工作的意义对于多数人来讲不过是需要把牛奶和面包放在自家的桌子上，喂养老人，孩子和自己。honor不重要，肚子饿比较重要。所以对饥饿的恐惧感，无形的督促我们每天早起晚归，拼命工作挣钱。
活在当下，我们好像生来就对所有的事情不满。一直想改善自己的状态，一个欲望达成后，下一个有自然浮现。&amp;ndash; 电影《before the sunset》
我对死亡最为恐惧是在七八岁的时候。那段日子，晚上关灯睡觉之后，我脑子都会想人要是死去之后，就什么都没有了。不管这世界如何精彩，天上的星星如何闪亮，宇宙如何变化，这一切都和一个死去的人没有一丁点关系。死去，意味着不存在了，你所有的思想，记忆，喜怒哀乐都不复存在了。每每想到此，我就特别的恐惧，恐惧那种不存在。这种恐惧，最近在早晨的梦里又出现了几次, 对不存在的无法接受又萦绕在脑中。不过也许人长大了，也就麻木了，洗漱之后，该上班上班，平日里嘈杂忙碌的生活会帮你忘却这种恐惧。
人到30，进入而立。有那么一瞬间，会觉得一切只能如此了，就按部就班的安稳地活着吧。只是希望自己在忙着挣钱，忙着处理各种各样生活工作中问题的时候，不要忘了Steve Jobs的这段话：
“Your time is limited, so don’t waste it living someone else’s life. Don’t be trapped by dogma – which is living with the results of other people’s thinking. Don’t let the noise of other’s opinions drown out your own inner voice. And most important, have the courage to follow your heart and intuition.</description>
    </item>
    
    <item>
      <title>音频编解码以及音乐GPU实时可视化效果实现</title>
      <link>https://cp0000.github.io/2018/06/16/audio/</link>
      <pubDate>Sat, 16 Jun 2018 10:58:22 +0000</pubDate>
      
      <guid>https://cp0000.github.io/2018/06/16/audio/</guid>
      <description>前言 在一些音乐播放器上（如上学时候用的播放器千千静听）会有一排 直方图 随着音乐节奏忽高忽低的跳动。你会好奇这个直方图的跳动是随着音乐的什么属性来做变换的，貌似有时候和音乐的节奏还挺搭的。要解释清楚这个问题，首先得了解什么声音，以及声音的原理。
声音 声音的原理 根据维基百科上所述：声音是一种波动；当演奏乐器、人说话或者敲击桌面时，声音的振动会引起介质——空气分子有节奏的振动，使周围的空气产生疏密变化，形成疏密相间的纵波，这就产生了声波，这种现象会一直延续到振动消失为止。
声音作为波的一种，频率和振幅就成了描述波的重要属性，频率的大小与我们通常所说的音高对应，而振幅影响声音的大小。声音可以被分解为不同频率不同强度的正弦波的叠加。这种变换（或分解）的过程，称为傅立叶变换(Fourier Transform)。
所以到这里，我们大致明白了音乐播放器上面的直方图其实是声音的频率和振幅的统计图。
声音的特性 响度（loudness）：人主观上感觉声音的大小（俗称音量），由“振幅”（amplitude）和人离声源的距离决定，振幅越大响度越大，人和声源的距离越小，响度越大。（单位：分贝dB） 音调（pitch）：声音的高低（高音、低音），由“频率”（frequency）决定，频率越高音调越高（频率单位Hz（hertz），赫兹)，人耳听觉范围 20～20k Hz。20Hz以下称为次声波，20k Hz以上称为超声波）例如，低音端的声音或更高的声音，如细弦声。频率是每秒经过给定点的声波数量，它的测量单位为赫兹。1000Hz表示每秒经过给定点的声波有1000个周期 音色（Timbre）：又称音品，波形决定了声音的音色。声音因不同物体材料的特性而具有不同特性，音色本身是一种抽象的东西，但波形是把这个抽象直观的表现。音色不同，波形则不同。典型的音色波形有方波，锯齿波，正弦波，脉冲波等。不同的音色，通过波形，完全可以分辨的。 乐音：有规则的让人愉悦的声音。噪音：从物理学的角度看，由发声体作无规则振动时发出的声音； 音频编解码 音频的编解码器需要分成硬件，软件两个部分讨论。硬件部分，音频编码器芯片（ADC）会把接收到的声波转换成PCM数据, 由于PCM占用存储资源太大，不利于传输和存储，所以需要利用音频编解码器软件对PCM数据进行压缩，得到如 FLAC/MP3/OGG 的音频文件。当我们播放一段数字音频文件的时候，则需要先进行软解码，也就是对压缩过的音频文件（FLAC/MP3/OGG）先解码成PCM，然后传送解码后的PCM给音频解码器（DAC），解码器将数字信号转换为模拟信号。
音频硬编码过程 信号的数字化就是将连续的模拟信号转换成离散的数字信号， 一般需要完成采样、量化和编码三个步骤,如下图所示。
采样是指用每隔一定时间间隔的信号样本值序列来代替原来在时间上连续的信号。 量化是用有限个幅度近似表示原来在时间上连续变化的幅度值，把模拟信号的连续幅度变为有限数量，有一定时间间隔的离散值。 编码则是按照一定的规律，把量化后的离散值用二进制数码表示。 上诉数字化过程称为脉冲编码调制（Pulse Code Modulation，缩写PCM）
PCM 的码率 采样率值 × 采样大小值 × 声道数 bps = 码率 例如: 一个采样率为44.1KHz，采样大小为16bit，双声道的PCM编码的WAV文件，它的数据速率则为 44.1K×16×2 =1411.2 Kbps。这表示存储一秒钟采样率为44.1KHz，采样大小为16bit，双声道的PCM编码的音频信号，需要176.4KB的空间，1分钟则约为10.34M MP3 MP3全称是MPEG-1orMPEG-2 Audio Layer III，它被设计来大幅降低音频数据量，它舍弃PCM音讯资料中，对人类听觉不重要的资料，从而达到了压缩成较小的档案。而对于大多数用户的听觉感受来说，MP3的音质与最初的不压缩音频相比没有明显的下降。
音频处理 音频傅立叶变换 了解了声音和音频编解码的基础知识之后，我们可以开始对音频进行相关应用处理了。那如何处理音频呢？首先用Audacity软件打开一段音频，会看到如下图所示的波形图。你会想，这乱糟糟，看起来没啥规律可循的波形的该如何处理。
就像我们处理图片的时候，会把像素点颜色分解成RGB三个通道（或者YCbCr,Lab 等其他颜色空间）进行处理一样，在处理音频的时候，我们需要对音频的波形进行分解。根据声音的特性，不同物体发出的声音频率范围是不一样的，如下图是不同乐器的频率范围：
所以我们可以把音频从时域转换到频域，然后对分解出来的各个频率进行操作。这里需要借助傅立叶变换完成音频从时域到频域的转换。
看不懂傅立叶变换的数学公式也没有关系，只要记住下面这张图就好。
如上图，对左边红色的音频时域声波进行傅立叶变换之后，分解成了一系列正弦波。而右边蓝色部分是针对分解的一系列正弦波的统计图，其中横轴是频率，纵轴是振幅。有了这张频谱图，我们可以很方便的处理音频了（如消除某一段频率等等）。
Demo 有了上面对音频做傅立叶变换后的频率数组，我们可以开始去实现一个音乐实时可视化Demo了。考虑到性能，以及跨平台，我们利用GPU搭配OpenGL编程去实现Demo。实现步骤如下图所示：
获取PCM数据 在iOS上，利用AVFoundation中的AVAudioEngine获取音乐的pcmbuffer，然后利用Accelerate framework中提供的DSP信号处理api，对pcmbuffer进行傅立叶变换。
加载音乐 NSString * audioPath = [[NSBundle mainBundle] pathForResource: @&amp;quot;bgm&amp;quot; ofType: @&amp;quot;.</description>
    </item>
    
    <item>
      <title>失败者才设定目标</title>
      <link>https://cp0000.github.io/2018/01/03/goals-are-for-losers/</link>
      <pubDate>Wed, 03 Jan 2018 19:31:06 +0000</pubDate>
      
      <guid>https://cp0000.github.io/2018/01/03/goals-are-for-losers/</guid>
      <description>Learn OpenCV 因为工作需要，我订阅了 Learn OpenCV 的邮件。Learn OpenCV 可以简单描述成是一个教学OpenCV的网站，网站的作者是 Satya Mallick,美国加州大学圣迭戈分校的博士，主要研究计算机视觉。网站上面的教程每个都是从原理和基础知识开始讲解，配合工程实现，直至最终完成Demo。每篇Blog都会配有c++和python 两个版本的source code，是个非常不错的学习OpenCV的网站。17年下半年开始，网站上也开始教学机器学习，深度学习相关的知识，同样保持了一贯浅显易懂的特点。
Goals are for losers 最近 Learn OpenCV 发送了一份邮件，标题叫Goals are for losers，直译成中文是目标是为失败者设定的。看起来很标题党的感觉，在我们的认知中，设定目标为了帮助我们把梦想实现，任务完成，是通往更好的自己的必经之路，怎么会是为失败者定制的了。
以下是对Goals are for losers这份邮件的翻译：
随着新年的到来，给新的一年设置目标看起来是一件很美妙的事。但如果你想完成某件事，而你只是设定了一个目标，那你大概率会失败。
假设你今年的目标是完全掌握计算机视觉中某个领域的全部知识。那得等到2018年结束的时候你才会知道你的目标是否完成了。如果你没完成目标，在2018年结束的时候，对这个结果，除了叹息接受，你无能为力。
目标是一个滞后的衡量标准, 你需要一个主导衡量标准
什么是主导衡量标准？主导衡量标准指的是能提前告知你每天是否接近目标。像“每天花两小时学习计算机视觉”就是一个主导衡量标准。
为了始终如一地执行主导措施，我们需要的是制定计划。我们的计划可以制定成早上5点到7点学习计算机视觉（美国人民这么拼？？？）。如果某天你没有完成计划，意味着你需要在那个周末加班把时间补起来。在制定计划的时候，我们需要明确定义在什么时间点做什么事情（计划的可执行也很重要，一个无法执行的计划也是没有意义的）。每天花一点时间这种计划是不会起作用的。
坚持执行计划，目标自然会达成，否则目标就是幻想。
我非常同意上述的观点，一定要为设定的目标制定详细的执行计划，然后按照计划一丝不苟的完成，这样目标才能达成。想来惭愧，我在17年6月份花了 ¥2000.00 参加了FaceAI的课程，但因为没有具体的计划，也缺少明确的目标，导致我购买的这个课程一点知识都没有学习到。
以上。</description>
    </item>
    
  </channel>
</rss>
