<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2019s on CP0000 - 一只特立独行的猪</title>
    <link>https://cp0000.github.io/2019/</link>
    <description>Recent content in 2019s on CP0000 - 一只特立独行的猪</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Wed, 20 Nov 2019 00:05:53 +0000</lastBuildDate><atom:link href="https://cp0000.github.io/2019/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>活到31</title>
      <link>https://cp0000.github.io/2019/11/20/31/</link>
      <pubDate>Wed, 20 Nov 2019 00:05:53 +0000</pubDate>
      
      <guid>https://cp0000.github.io/2019/11/20/31/</guid>
      <description>你所想要的那样东西，你的欲望对象本身他在结构上必然将使你更痛苦。你对他的追求不会滋养你的生命，反而会阻碍你的生命。 - Lauren Berlan
也许是自己没有以前那么sensitive了，也许是因为工作过于忙碌。从计划写这篇文章到现在为止，已经过去了一个半月了，每每打开文档编辑器，脑子里面一片空白，发现自己没有什么值得写的。
11年大学毕业前后，我分别看了Steve Jobs在斯坦福关于follow your heart主题的演讲，和另外一片讲年轻人该如何去寻找自己目标的文章。现如今8年过去了，文中方法我尝试过，也试图得出了一些关于自己目标的关键词。但现在看来，那些词都太抽象，不具体，以至于在写下那些关键字的第二天就忘记自己写过啥了，但这8年中，自己是一直在努力尝试着去找出自己最想做的事情，最想成为的人。只是能想清楚这件事并不容易，我至今还没想清楚。
而乔布斯演讲中那一句“your time is limited”却始终在我脑子里打转。时间，是每个人的原始财富。工人拿时间换工钱，学生拿时间换知识，父母拿时间养育下一代，换取基因的繁殖。我们每个人拥有着时间这一原始财富，然后在社会影响和自我意识决定下拿时间去换取自己想要的东西。
而现如今，我们很容易被生活带入一个循环，然后就此习惯了这种循环。每天上班，下班，打卡，开会，看电影，吃火锅，跑步，打游戏，今天重复昨天，这周重复着上周；我甚至说不出来17年，18年，19年，三年有何不同。现代社会让工作，生活，消遣占住我们所有的精力，让我们的眼睛从早上起床睁开到晚上睡觉闭上，一刻都不得闲，各式各样的垃圾信息刺激着你的脑神经。
工作生活在不停的重复着重复，个人的时间年轮也越滚越粗。随之而来有体力的下降，创造力的下降，还有对生活的敏感度的下降。你不在是一个敏感的人，不会为了一点小事而伤感，也不会因为一点压力而睡不着觉。你变得tough，甚至麻木，就像一台工作机器，接受一个又一个任务，然后机械的去完成它。但 your time is limited, 时间是有限的，每件事情都有他的窗口期，感情是这样，工作中的某个机会是这样，理想也是这样。20岁年薪百万和30岁年薪百万，感受肯定差异很大，不同的年纪相同的事物体验差别很大，我们能做的就是在尽可能年轻的时候去体验尽可能多的事情。
人到31，还在谈理想是有点尴尬，况且有时候会觉得日子不是只给自己过了。父母年纪大了，自己也该成家立业了，而工作更是不敢怠慢。
西方人思考人生角度是更多的考虑自己，而我们不行，即使我受了很多西方文化影响，纵然我个人很多时候是思考「我」该怎么做，但我们父辈不是，身边的人不是，我们生活的这个社会在道德要求你需要去从家庭，从父母的角度思考问题，你有你的历史任务。而作为一个年到31，还没成家的，在上海工作的一线程序员，如何在感情，事业，生活三者中得到平衡，从中获得幸福感，看起来是接下来数年我要寻找的答案。</description>
    </item>
    
    <item>
      <title>逻辑回归</title>
      <link>https://cp0000.github.io/2019/03/31/logistic-regression/</link>
      <pubDate>Sun, 31 Mar 2019 14:41:59 +0000</pubDate>
      
      <guid>https://cp0000.github.io/2019/03/31/logistic-regression/</guid>
      <description>逻辑回归是二分类任务中最常用的机器学习算法之一。它的设计思路简单，易于实现，可以用作性能基准，且在很多任务中都表现良好。
本文从以下几个方面讲述逻辑回归：
什么是逻辑回归？ 它是如何工作的。 逻辑回归 vs 线性回归 优缺点 何时适用 多分类任务（OvA, OvO） 其他分类算法 总结 什么是逻辑回归 和很多其他机器学习算法一样，逻辑回归也是从统计学中借鉴过来的，尽管名字里有回归两个字，但它不是一个需要预测连续结果的回归算法。与之相反，逻辑回归是二分类任务的首选方法。它输出一个0到1之间的离散尔值结果。简单来讲，它的结果不是0就是。
癌症检测算法可看做是逻辑回归问题的一个简单例子，这种算法输入病理图片并且应该辨别患者患有癌症（1）或没有癌症（0）。
它是如何工作的？ 逻辑回归通过使用其固有的逻辑函数估计概率，来衡量因变量（目标预测标签）与一个或者多个自变量（特征）之间的关系。 然后这些概率必须二值化才能真的进行预测。这就是逻辑函数的任务，也称为sigmoid函数。sigmoid函数是一个S形曲线，它可以将任意实数值映射到介于0和1之间的值，但不能取0或1.然后使用阈值分类器将0和1之间的值转换为0或1. 下图说明了逻辑回归得出预测所需的所有步骤。 假设函数 （Hypothesis function） 逻辑回归的假设函数形式如下： 这个函数称为sigmoid函数，也称为逻辑函数，其函数曲线如下： 从上图可以看到sigmoid函数是一个s形的曲线，它的取值在[0,1]之间，在远离0的地方函数的值会很快接近0/1.这个性质使我们能够以概率的方式来解释。 一个机器学习的模型，实际上就是把决策函数限定在某一组条件下，这组限定条件就决定了模型的假设空间。当然，我们还希望这组限定条件简单而合理。而逻辑回归模型所做的假设是： 这里的g(h)是上面提到的sigmoid函数，相应的决策函数是： 选择0.5作为阈值是一个一般的做法，实际应用时特定情况可以选择不同阈值。
决策边界（Decision Boundary） 决策边界，也称为决策面，是用于在N维空间，将不同类别样本分开的平面或曲面。 线性决策边界： 决策边界： -3 + x1 +x2 = 0
非线性决策边界 决策边界： -1 + x1^2 +x2^2 = 0
决策边界其实是一个方程，在逻辑回归中，决策边界由theta&amp;rsquo; X=0定义。 假设函数（h=g(z)）用于计算样本属于某种类别的可能性；决策函数(h=1(g(z)&amp;gt;0.5))用于计算样本的类别；决策边界（θ^Tx=0）是一个方程，用于标识出分类函数（模型）的分类边界。
代价函数（Cost Function） 逻辑回归中，采用如下的形式计算样本的代价值：
整合一下，得到逻辑回归中的代价函数：
优化方法 在逻辑回归中，使用梯度下降法对代价函数进行优化，完整形式如下： 注意： 逻辑回归和线性回归问题中，梯度下降算法的形式看上去一致，但实际上两者完全不同，因为假设函数是不同的，需要特别注意这一点。
其向量化实现（vectorized implementation）如下： 逻辑回归 vs 线性回归 逻辑回归得到一个离散的结果，线性回归得到一个连续的结果。预测房价的模型返回连续结果，是线性回归。癌症检测的结果是你有癌症或没有，是逻辑回归。
优缺点 逻辑回归是一种被人们广泛使用的算法，它非常高效，不需要太大的计算量，又通俗易懂，不需要缩放输入特征，不需要任何调整，且容易调整，并且输出校准好的预测概率。与线性回归一样，当你去掉和输出变量无关的属性以及相似度高的属性时，逻辑回归效果确实会更好。因此特征处理在逻辑回归和线性回归的性能方面起着重要的作用。
逻辑回归的另一个优点是它非常容易实现，且训练起来很高效。 它的一个缺点就是我们不能用逻辑回归来解决非线性问题，因为它的决策边界是线性的。</description>
    </item>
    
    <item>
      <title>机器学习基础知识：熵，交叉熵，相对熵</title>
      <link>https://cp0000.github.io/2019/03/02/entropy/</link>
      <pubDate>Sat, 02 Mar 2019 16:02:21 +0000</pubDate>
      
      <guid>https://cp0000.github.io/2019/03/02/entropy/</guid>
      <description>简介 信息熵是随机数据源产生信息的均量。信息熵代表的是随机变量或整个系统的不确定性，熵越大，随机变量或系统的不确定性就越大。
计算 一枚正常硬币进行若干次抛投，这个事件的熵是1bit，因为结果不外乎两个 - 正面或反面，可以表示为0，1编码，而且两个结果彼此之间相互独立。但如果一枚硬币的两面完全相同，那抛硬币事件的熵为零，因为结果能被准确预测。
定义 信息熵的数学公式如下：
其中 P 为X的概率质量函数，E为期望函数，而I(x)是X的信息量。I(X)本身是个随机变数。当取自有限样本时，熵的公式可以表示为：
所以熵的本质是香农信息量 log(1/p)的期望；一个事件结果的出现概率越低，对其编码的bit长度就越长。以期望在整个随机事件的无数次重复试验中，用最少的bit去记录整个实验历史，即无法压缩的表达，代表了真正的信息量。
交叉熵 一个系统有一个真实的概率分布，也叫真实分布，根据真实分布，我们能够找到一个最优策略，以最小的代价消除系统的不确定性，而这个代价大小就是信息熵。
多数情况下，我们并不知道系统的真实分布，如抛硬币例子，如果硬币两面一样，但我们不知道这一信息，以为两面不一样，两面不一样是一个非真实分布。交叉熵，是用来衡量在给定的真实分布下，使用非真实分布所指定的策略消除系统的不确定性所需要付出的努力大小。
交叉熵的公式为：
其中p为真实分布，q为非真实分布。交叉熵越低，意味着q越接近p。所以在机器学习分类算法中，我们总是最小化交叉熵，交叉熵越低，间接证明算法推算出的非真实分布q越接近真实分布p。
深度学习中交叉熵损失函数[Cross Entropy Loss]；
相对熵（KL散度） 相对熵又称KL散度，是为了衡量不同策略之间的差异，即：
假设f(x)为真实分布p，g(x)为非真实分布q，则上述相对熵为：</description>
    </item>
    
    <item>
      <title>2018年度总结</title>
      <link>https://cp0000.github.io/2019/01/20/2018-summary/</link>
      <pubDate>Sun, 20 Jan 2019 20:09:46 +0000</pubDate>
      
      <guid>https://cp0000.github.io/2019/01/20/2018-summary/</guid>
      <description>
文娱 电影 中国 一一 - ⭐️⭐️⭐️⭐️⭐️ 红海行动 - ⭐️⭐️⭐️⭐️ 影 - ⭐️⭐️⭐️ 无双 - ⭐️⭐️⭐️ 我不是药神 - ⭐️⭐️⭐️ 好莱坞 蜘蛛侠-平行宇宙 - ⭐️⭐️⭐️⭐️ 杰出公民 - ⭐️⭐️⭐️⭐️ 碟中谍6：全面瓦解 - ⭐️⭐️⭐️⭐️ 奇迹男孩 - ⭐️⭐️⭐️ 头号玩家 - ⭐️⭐️⭐️ 海王 - ⭐️⭐️⭐️ 寂静之地 - ⭐️⭐️⭐️ 第六感生死缘 - ⭐️⭐️⭐️ 美国丽人 - ⭐️⭐️⭐️ 古墓丽影：源起之战 - ⭐️⭐️ 黑豹 - ⭐️⭐️ 复仇者联盟3 - ⭐️⭐️ 蚁人2 - ⭐️ 金刚-骷髅岛 - ⭐️ 日本 无人知晓 - ⭐️⭐️⭐️ 其他 看不见的客人 - ⭐️⭐️⭐️⭐️ 斯大林之死 - ⭐️⭐️⭐️⭐️ 一个叫欧维的男人决定去死 - ⭐️⭐️⭐️⭐️ 恐怖直播 - ⭐️⭐️⭐️⭐️ 艾尔酒吧 - ⭐️⭐️⭐️ 普通女人 - ⭐️⭐️⭐️ 燃烧 - ⭐️⭐️⭐️ 厕所英雄 - ⭐️⭐️ 美剧-英剧-日剧-纪录片 辛普森：美国制造 - ⭐️⭐️⭐️⭐️⭐️ Ugly Delicious - ⭐️⭐️⭐️⭐️⭐️ 风骚律师 - 第四季 - ⭐️⭐️⭐️⭐️ 毒枭：墨西哥 - ⭐️⭐️⭐️⭐️ 梅尔罗斯 - ⭐️⭐️⭐️⭐️ 硅谷第五季 - ⭐️⭐️⭐️⭐️ 非自然死亡 - ⭐️⭐️⭐️⭐️ 西部世界第二季 - ⭐️⭐️⭐️ 保镖 - ⭐️⭐️⭐️ 利器 - ⭐️⭐️⭐️ 杀死伊芙 - ⭐️⭐️⭐️ 了不起的麦瑟尔夫人 - ⭐️⭐️⭐️ 9号秘事第四季 - ⭐️⭐️⭐️ 音乐 Kendrick Lamar 书籍 那不勒斯四部曲（1）- 我的天才女友 - ⭐️⭐️⭐️⭐️⭐️ 那不勒斯四部曲（2）- 新名字的故事 - ⭐️⭐️⭐️⭐️ 那不勒斯四部曲（3）- 离开的，留下的 - ⭐️⭐️⭐️⭐️ 那不勒斯四部曲（4）- 失踪的孩子 - ⭐️⭐️⭐️⭐️ 失明症漫记 - ⭐️⭐️⭐️⭐️ 我是个年轻人，我心情不太好- ⭐️⭐️⭐️ 富士山禁恋- ⭐️⭐️⭐️ Podcast 灭茶苦茶 文化土豆 硅谷早知道 Blow Your Mind The Dave Chang Show 996 Podcast by GGV 体育 2018年世界杯 1/8 决赛：法国-阿根廷 17-18 NBA季后赛 西部决赛 - 金州勇士-休斯顿火箭队 工作 年度编程语言 - Python 年度技术点 - DeepLearning 年度App - 微信读书，网易有钱 年度工具 - PyCharm Ce 年度硬件 - AirPods，15寸mbp 年度公开课 - 3blue1brow, 李宏毅机器学习课程 </description>
    </item>
    
  </channel>
</rss>
